{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of years\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "extracted_data = []\n",
    "party_data = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    # URL of the JSON data\n",
    "    url = f'https://zpravy.udhpsh.cz/export/vfz{year}-index.json'\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON data\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract relevant data\n",
    "        for party in data['parties']:\n",
    "            for file in party['files']:\n",
    "                extracted_data.append({\n",
    "                    'year': year,\n",
    "                    'key': data['election']['key'],\n",
    "                    'ic': party['ic'],\n",
    "                    'subject': file['subject'],\n",
    "                    'url': file['url']\n",
    "                })\n",
    "                party_data.append({\n",
    "                    'ic': party['ic'],\n",
    "                    'shortName': party['shortName'],\n",
    "                    'longName': party['longName']\n",
    "\n",
    "                })\n",
    "                \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for year {year}: {response.status_code}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(extracted_data)\n",
    "df_party = pd.DataFrame(party_data).drop_duplicates(subset=['ic'])\n",
    "df_party.rename(columns={ 'ic': 'party_key','shortName': 'party_short', 'longName': 'party_long'}, inplace=True)\n",
    "\n",
    "df_party.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/D_party.csv', index=False)\n",
    "# Print the DataFrame\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cprijmy = df[df['subject'] == 'cprijmy']\n",
    "df_cvydaje = df[df['subject'] == 'cvydaje']\n",
    "df_zamest = df[df['subject'] == 'zamest']\n",
    "df_polinst = df[df['subject'] == 'polinst']\n",
    "df_podil = df[df['subject'] == 'podil']\n",
    "df_penizefo = df[df['subject'] == 'penizefo']\n",
    "df_bupfo = df[df['subject'] == 'bupfo']\n",
    "df_penizepo = df[df['subject'] == 'penizepo']\n",
    "df_buppo = df[df['subject'] == 'buppo']\n",
    "df_dluhy = df[df['subject'] == 'dluhy']\n",
    "df_dedictvi = df[df['subject'] == 'dedictvi']\n",
    "df_clenove = df[df['subject'] == 'clenove']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\n",
    "df_cprijmy,\n",
    "df_cvydaje,\n",
    "df_zamest,\n",
    "df_podil,\n",
    "df_penizefo,\n",
    "df_penizepo,\n",
    "# df_polinst,\n",
    "# df_bupfo,\n",
    "# df_buppo,\n",
    "# df_dluhy,\n",
    "# df_dedictvi,\n",
    "# df_clenove,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_json(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        return response.json()  # Return parsed JSON\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None  # Return None in case of error\n",
    "\n",
    "# Fetch JSON for each URL and store it in a new column\n",
    "# df_head['json_response'] = df_head['url'].apply(fetch_json)\n",
    "# df_head.to_csv('financovani.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    subject['json_response'] = subject['url'].apply(fetch_json)\n",
    "    subject.to_csv(f'{subject.iloc[0][\"subject\"]}.csv', index=False, encoding='utf-8')\n",
    "    print(f'{subject.iloc[0][\"subject\"]} done')\n",
    "    \n",
    "    # Step 1: Expand the JSON into a tabular format\n",
    "    exploded_df = subject.explode('json_response')\n",
    "\n",
    "    # Step 2: Normalize the JSON data\n",
    "    expanded_df = pd.json_normalize(exploded_df['json_response'])\n",
    "\n",
    "    # Add meaningful context from the original DataFrame\n",
    "    result_df = exploded_df[['year',  'ic']].reset_index(drop=True)\n",
    "    result_df = pd.concat([result_df, expanded_df], axis=1)\n",
    "    result_df.to_csv(f'/Users/zackrawr/Developer/Python_WS/public_service/CURATED/{subject.iloc[0][\"subject\"]}.csv', index=False, encoding='utf-8')\n",
    "    print(f'{subject.iloc[0][\"subject\"]} done in curated')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing FO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/penizefo.csv')\n",
    "df_fo = df_fo.drop(columns=['year', 'ic', 'date', 'money', 'addrCity'])\n",
    "df_fo = df_fo.drop_duplicates(subset=['lastName', 'firstName', 'birthDate'])\n",
    "df_fo['donor_key'] =  'fo.' + df_fo.index.astype(str)\n",
    "df_fo['donor_form'] =  'FO'\n",
    "df_fo['titleBefore'] = df_fo['titleBefore'].fillna('')\n",
    "df_fo['titleAfter'] = df_fo['titleAfter'].fillna('')\n",
    "df_fo['donor_name'] = df_fo.apply(lambda row: f\"{row['titleBefore']} {row['firstName']} {row['lastName']} {row['titleAfter']}\".strip(), axis=1)\n",
    "df_fo['donor_name'] = df_fo['donor_name'].str.replace('  ', ' ')  # Remove any double spaces\n",
    "df_fo.head()\n",
    "df_fo.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_FO.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penizefo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/penizefo.csv')\n",
    "df_fo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_FO.csv')\n",
    "df_merged = pd.merge(df_penizefo, df_fo, on=['lastName', 'firstName', 'birthDate'], how='left')\n",
    "result_df = df_merged.drop(['lastName', 'firstName', 'titleBefore_x', 'titleAfter_x', 'birthDate', 'addrCity','titleBefore_y','titleAfter_y','donor_name'], axis=1)\n",
    "result_df.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/F_dary_fo.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/penizepo.csv')\n",
    "df_po = df_po.drop(columns=['year', 'ic', 'date', 'money', 'addrStreet', 'addrCity', 'addrZip'])\n",
    "df_po = df_po.drop_duplicates(subset=['companyId'])\n",
    "df_po['donor_key'] =  'po.' + df_po.index.astype(str)\n",
    "df_po['donor_form'] =  'PO'\n",
    "df_po = df_po.rename(columns={'company': 'donor_name'})\n",
    "df_po.head()\n",
    "df_po.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_PO.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penizepo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/penizepo.csv')\n",
    "df_po = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_PO.csv')\n",
    "df_merged = pd.merge(df_penizepo, df_po, on=['companyId'], how='left')\n",
    "result_df = df_merged.drop(['companyId', 'company','addrStreet', 'addrCity', 'addrZip', 'donor_name'], axis=1)\n",
    "result_df.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/F_dary_po.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing dary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penizepo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/F_dary_po.csv')\n",
    "df_penizefo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/F_dary_fo.csv')\n",
    "df_merged = pd.concat([df_penizepo, df_penizefo])\n",
    "df_merged['year'] =  df_merged['year'].astype(str) + '-01-01'\n",
    "df_merged.rename(columns={'year': 'date_year', 'ic': 'party_key', 'date': 'donor_date', 'money': 'donor_amount'}, inplace=True)\n",
    "df_merged = df_merged[df_merged['donor_amount'] != 0]\n",
    "df_merged.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/F_dary.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128096\n",
      "112642\n"
     ]
    }
   ],
   "source": [
    "print(len(df_merged))\n",
    "df_merged = df_merged[df_merged['donor_amount'] != 0]\n",
    "print(len(df_merged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing rozvaha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprijmy = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/cprijmy.csv')\n",
    "cvydaje = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/cvydaje.csv')\n",
    "cprijmy['key'] = 'P_' + cprijmy['key'].astype(str)\n",
    "cvydaje['key'] = 'V_' + cvydaje['key'].astype(str)\n",
    "df_merged = pd.concat([cprijmy, cvydaje])\n",
    "df_merged = df_merged.drop(columns=['description'])\n",
    "df_merged['year'] =  df_merged['year'].astype(str) + '-01-01'\n",
    "df_merged.rename(columns={'year': 'date_year', 'ic': 'party_key', 'key': 'bod_key'}, inplace=True)\n",
    "df_merged.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/F_rozvaha.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_PO.csv')\n",
    "df_fo = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_FO.csv')\n",
    "df_merged = pd.concat([df_po, df_fo])\n",
    "df_merged = df_merged[['donor_key','donor_name','donor_form','birthDate','companyId']] \n",
    "df_merged.rename(columns={'birthDate': 'date_DOB', 'companyId': 'ICO'}, inplace=True)\n",
    "df_merged['donor_name'] =df_merged['donor_name'].str.strip('\"').str.replace('\"', '')\n",
    "df_merged.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/D_donor.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_key</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>donor_form</th>\n",
       "      <th>date_DOB</th>\n",
       "      <th>ICO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>po.0</td>\n",
       "      <td>ABF, a.s.</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63080575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po.2</td>\n",
       "      <td>Advokátní kancelář Belha, Vacíř &amp; spol., s.r.o.</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28498038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>po.3</td>\n",
       "      <td>DDX Czech a.s.</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5401275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>po.4</td>\n",
       "      <td>ERDEX a.s.</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27182533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>po.5</td>\n",
       "      <td>Finep Prosek bytová k.s.</td>\n",
       "      <td>PO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24716847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  donor_key                                       donor_name donor_form  \\\n",
       "0      po.0                                        ABF, a.s.         PO   \n",
       "1      po.2  Advokátní kancelář Belha, Vacíř & spol., s.r.o.         PO   \n",
       "2      po.3                                   DDX Czech a.s.         PO   \n",
       "3      po.4                                       ERDEX a.s.         PO   \n",
       "4      po.5                         Finep Prosek bytová k.s.         PO   \n",
       "\n",
       "  date_DOB       ICO  \n",
       "0      NaN  63080575  \n",
       "1      NaN  28498038  \n",
       "2      NaN   5401275  \n",
       "3      NaN  27182533  \n",
       "4      NaN  24716847  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stripped = df_merged\n",
    "df_stripped['donor_name'] =df_stripped['donor_name'].str.strip('\"').str.replace('\"', '')\n",
    "df_stripped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing zamestnanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zamest = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/zamest.csv')\n",
    "df_zamest['year'] =  df_zamest['year'].astype(str) + '-01-01'\n",
    "df_zamest.rename(columns={'year': 'date_year', 'ic': 'party_key', 'job': 'job_desc', 'number': 'job_count'}, inplace=True)\n",
    "\n",
    "df_job = pd.read_csv('/Users/zackrawr/Developer/Python_WS/public_service/CURATED/D_job.csv')\n",
    "df_job.reset_index(inplace=True, drop=False)\n",
    "df_job.rename(columns={'index': 'job_key'}, inplace=True)\n",
    "df_job.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/D_job.csv', index=False, encoding='utf-8')\n",
    "\n",
    "df_merged = pd.merge(df_zamest, df_job, on=['job_desc'], how='left')\n",
    "df_merged = df_merged[['date_year','party_key','job_key','job_count']] \n",
    "df_merged.to_csv('/Users/zackrawr/Developer/Python_WS/public_service/PBI/F_zamestnanci.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_key</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>job_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Administraivní práce</td>\n",
       "      <td>Administrative and Support Roles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>administrativa</td>\n",
       "      <td>Administrative and Support Roles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Administrativa</td>\n",
       "      <td>Administrative and Support Roles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>administrativa - DPČ - zam. malého rozsahu</td>\n",
       "      <td>Administrative and Support Roles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>administrativa (05-09/2022)</td>\n",
       "      <td>Administrative and Support Roles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_key                                    job_desc  \\\n",
       "0        0                        Administraivní práce   \n",
       "1        1                              administrativa   \n",
       "2        2                              Administrativa   \n",
       "3        3  administrativa - DPČ - zam. malého rozsahu   \n",
       "4        4                 administrativa (05-09/2022)   \n",
       "\n",
       "                          job_group  \n",
       "0  Administrative and Support Roles  \n",
       "1  Administrative and Support Roles  \n",
       "2  Administrative and Support Roles  \n",
       "3  Administrative and Support Roles  \n",
       "4  Administrative and Support Roles  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
